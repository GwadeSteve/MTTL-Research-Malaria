
\begin{tikzpicture}[node distance=2cm and 2.2cm]
    % --- MAIN FLOW ---
    \node (input) {Input $\mathbf{z}$};
    \node[op, right=5cm of input] (add) {$+$};
    \node[right=5cm of add] (output) {Output $\mathbf{z}'$};

    % --- LoRA PATH ---
    \coordinate (lora_center) at ($(input)!0.5!(add)$);
    \node[cuboid, trainable, below=2cm of lora_center, minimum height=1.8cm] (lora_a) 
        {$\mathbf{W}_A$ \\[-2pt] {\scriptsize $C \times r$}};
    \node[cuboid, trainable, right=2.2cm of lora_a, minimum height=1.2cm] (lora_b) 
        {$\mathbf{W}_B$ \\[-2pt] {\scriptsize $r \times C$}};
    \node[op, right=2.2cm of lora_b] (scale) {$\times \tfrac{\alpha}{r}$};

    % --- ARROWS ---
    \draw[arrow] (input.east) -- (add.west);
    \draw[arrow] (add.east) -- (output.west);
    \draw[loraarrow] (input.east) ++(1.0,0) |- (lora_a.north);
    \draw[loraarrow] (lora_a.east) -- (lora_b.west);
    \draw[loraarrow] (lora_b.east) -- (scale.west);
    \draw[loraarrow] (scale.north) |- (add.south);

    % --- ANNOTATIONS ---
    \node[lorabox, fit=(lora_a)(lora_b)(scale)] {};
    \node[blocktitle, above=1.5cm of lora_center] {};
\end{tikzpicture}
%\caption{
%    \textbf{The LoRA Module.} This is the base of our architecture, the adapter modifies an input feature vector $\mathbf{z}$ using a trainable low-rank path. 
%    This path projects $\mathbf{z}$ through $W_A \in \mathbb{R}^{C \times r}$ and $W_B \in \mathbb{R}^{r \times C}$, 
%    before scaling the result and adding it back to the original input. The equation is: 
%    $\mathbf{z}' = \mathbf{z} + \tfrac{\alpha}{r} \, W_B W_A \mathbf{z}$.
%}