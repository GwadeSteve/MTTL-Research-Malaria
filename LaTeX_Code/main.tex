%\documentclass[english,12pt,a4paper,twoside,openright]{report}
\documentclass[english,12pt,a4paper]{report}

\usepackage[a4paper,tmargin=2.0cm,bmargin=2.0cm,rmargin=2cm,lmargin=2cm]{geometry}
\usepackage[utf8]{inputenc} 

\usepackage{float}
\usepackage{subcaption}

\usepackage{amssymb, amsfonts}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{adjustbox}
\usepackage{algpseudocode}
\usepackage{csquotes}
\usepackage{xcolor}
\definecolor{thesisblue}{RGB}{20, 68, 106}
\definecolor{thesisgray}{RGB}{80, 80, 80}
\usepackage{lmodern}
\usepackage{array}
\usepackage{booktabs} 
\usepackage{tabularx}
\newcolumntype{Y}{>{\centering\arraybackslash}X}

\usepackage{enumitem} 
\usepackage{colortbl}
\usepackage{lscape}   

\usepackage{pgfplots}  
\usepgfplotslibrary{groupplots}
\pgfplotsset{compat=1.18} 

\definecolor{highlightcolor}{RGB}{218, 232, 252} 
\usepackage{collcell}
\newcommand{\maxval}[1]{\pgfmathparse{#1}\ifdim\pgfmathresult pt=\thisrowmax pt \bfseries\cellcolor{highlightcolor}{#1}\else{#1}\fi}
\newcolumntype{H}{>{\collectcell\maxval}c<{\endcollectcell}} % H for Highlight

\usepackage{float}

\usepackage{etoolbox}
\usepackage{tabularray}

\usepackage{tikz}
\usetikzlibrary{
	positioning,
	fit,
	arrows.meta,
	shapes.geometric,
	calc,
	matrix,
	patterns,
	shadows,
	backgrounds,
	decorations.pathreplacing,
	shapes.misc
}

\tikzset{
	% For 3D-like convolutional layers
	cuboid/.style={
		shape=trapezium,
		trapezium left angle=70,
		trapezium right angle=-70,
		shape border rotate=90,
		minimum width=2.2cm,
		minimum height=1cm,
		draw, thick,
		align=center,
		font=\small
	},
	% Default cuboid color (Frozen)
	cuboidfill/.style={
		fill=blue!20
	},
	% Style for trainable components (sets cuboid color to orange)
	trainable/.style={
		fill=orange!30
	},
	% Style for generic blocks
	block/.style={
		rectangle, draw, thick,
		minimum width=3cm, minimum height=1.5cm, align=center,
		rounded corners=3pt
	},
	% Standard block for operations
	op/.style={
		circle, draw, thick, fill=gray!10, minimum size=0.8cm
	},
	% Main arrows for data flow
	arrow/.style={
		-Stealth, thick, draw=black!80
	},
	% Orange LoRA arrows
	loraarrow/.style={
		-Stealth, thick, draw=orange!80!black
	},
	% Dashed highlight around LoRA path
	lorabox/.style={
		draw=orange!70!black, dashed, thick,
		inner sep=6pt, rounded corners
	},
	% Title for a diagram section
	blocktitle/.style={
		font=\sffamily\bfseries\small, text=black!90
	}, 
	outnode/.style={
		rectangle, draw, fill=blue!10, rounded corners, minimum height=1cm
	}
}

\renewcommand{\familydefault}{\rmdefault} 
\usepackage{mathpazo}                   
\usepackage{microtype}          
\usepackage{setspace}               
\setstretch{1.2}                          

\usepackage[Lenny]{fncychap}
\usepackage{titlesec}

\titleformat*{\section}{\Large\bfseries\sffamily}       
\titleformat*{\subsection}{\large\bfseries\sffamily}    
\titleformat*{\subsubsection}{\normalsize\bfseries\sffamily} 

\titleformat{\chapter}[display]{\sf\bfseries\LARGE}{\vspace{-10ex}
	\filleft\MakeUppercase{\chaptertitlename}~\Huge\thechapter}{4ex}
	{\titlerule\vspace{2ex}\filright}[\vspace{2ex}\titlerule]

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyfoot[LE,RO]{\tiny Master of Science in Data Science and Artificial Intelligence}
\rhead{}
\lfoot{\footnotesize\tiny\textbf{Gwade Steve}}
\rfoot{\footnotesize\tiny\textbf{MTTL and Application to Malaria Detection}}

\usepackage[english]{babel}
\usepackage{verbatim}
\usepackage{url}
\usepackage{lipsum}
\usepackage{csquotes}

\usepackage{calc,amsfonts,amssymb,amsthm,latexsym}
\usepackage{tocloft}
\usepackage[centertags]{amsmath}

\newcommand{\listequationsname}{List of Equations}
\newlistof{myequations}{equ}{\listequationsname}

\setlength{\cftmyequationsnumwidth}{1cm} 

\newcommand{\myequations}[1]{%
	\addcontentsline{equ}{myequations}{\protect\numberline{\theequation}#1}}

\usepackage{fancybox,wrapfig,exscale,colortbl,tcolorbox,frcursive,empheq,multicol,varwidth,lipsum}
\usepackage{pgf,tikz}
\usetikzlibrary{arrows,calc}
\usepackage{eso-pic,bclogo}
\usepackage[all]{xy}

\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	citecolor=teal,
	urlcolor=magenta,
	filecolor=orange,
	pdfauthor={Gwade Steve},
	pdftitle={Multi-Task Transfer Learning and Application to Malaria Detection}
}

% BIBLIOGRAPHY / REFERENCES
%\usepackage[backend=biber, style=numeric, sorting=none]{biblatex} 
\usepackage[backend=biber, style=authoryear, maxcitenames=1, maxbibnames=5, sorting=nyt]{biblatex}
\addbibresource{references.bib}

\DeclareFieldFormat{year}{\textcolor{teal}{#1}}

\DeclareNameFormat{author}{%
	\textbf{\namepartfamily}%
	\ifthenelse{\value{listcount}<\value{liststop}}{\addcomma\space}{}%
}

\setlength\bibitemsep{0.1em} 
\setlength{\bibhang}{1em}
\DeclareFieldFormat[article]{journaltitle}{\mkbibemph{#1}}

\usepackage{acro}
\usepackage{longtable} 
\usepackage{multicol}

\usepackage[ruled,vlined]{algorithm2e}
\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}

\input{accronyms}

\acsetup{
	make-links = true,
	first-style = long-short,
	list/name = {List of Acronyms},
	list/heading = none,
	list/sort = true,
	list/template = description,
	pages/display = first
}

\newtheorem{exo}{{Exercice}}[chapter]
\newtheorem{remark}{{Remarque}}[chapter]
\newtheorem{definition}{DÃ©finition}[chapter]
\newtheorem{example}{{Exemple}}[chapter]
%\input{Setup/preamble}

\renewcommand{\cftchapleader}{\cftdotfill{\cftdotsep}}

\makeatletter
\patchcmd{\@chapter}{\addcontentsline{toc}{chapter}{#1}}{}{}{}
\patchcmd{\@section}{\addcontentsline{toc}{section}{#1}}{}{}{}
\patchcmd{\@subsection}{\addcontentsline{toc}{subsection}{#1}}{}{}{}
\patchcmd{\@subsubsection}{\addcontentsline{toc}{subsubsection}{#1}}{}{}{}
\makeatother

\begin{document}

% TITLE PAGE
\input{Pages/titlepage}

\pagestyle{fancy} 
\pagenumbering{roman}

% -------------------------------
% DECLARATION
% -------------------------------
\chapter*{Declaration}
\thispagestyle{plain}
\addcontentsline{toc}{chapter}{Declaration}
\input{Pages/declaration}

% -------------------------------
% ABSTRACT & ACKNOWLEDGMENTS
% -------------------------------

\chapter*{Acknowledgments}
\thispagestyle{plain}
\addcontentsline{toc}{chapter}{Acknowledgments}
\input{Pages/acknowledgment}

\chapter*{Abstract}
\thispagestyle{plain}
\addcontentsline{toc}{chapter}{Abstract}
\input{Pages/abstract}

\chapter*{Summary}
\thispagestyle{plain}
\addcontentsline{toc}{chapter}{Summary}
\input{Pages/summary}

% TOC
\newpage
\tableofcontents
\cleardoublepage

\chapter*{List of Acronyms}
\addcontentsline{toc}{chapter}{List of Acronyms}
{\small
	\setlength{\columnsep}{1cm} 
	\begin{multicols*}{2}
		\raggedright
		\let\olddescription\description
		\renewenvironment{description}{
			\olddescription
			\setlength{\itemsep}{0pt}   
			\setlength{\parsep}{0pt}    
			\setlength{\topsep}{0pt}    
			\setlength{\partopsep}{0pt} 
		}{\endlist}
		\printacronyms
	\end{multicols*}
}
\cleardoublepage

% LIST OF FIGURES
\chapter*{List of Figures}
\addcontentsline{toc}{chapter}{List of Figures}
\vspace*{-2.5cm}
\begingroup
\normalsize
\setlength{\cftfignumwidth}{2.5em}      
\setlength{\cftfigindent}{0pt}          
\setlength{\cftbeforefigskip}{0pt}      
\setlength{\cftaftertoctitleskip}{0pt}  
\renewcommand{\listfigurename}{}        
\listoffigures
\endgroup
\cleardoublepage

% LIST OF TABLES
\chapter*{List of Tables}
\addcontentsline{toc}{chapter}{List of Tables}
\vspace*{-2.5cm}  
\begingroup
\normalsize
\setlength{\cfttabnumwidth}{2.5em}       
\setlength{\cfttabindent}{0pt}           
\setlength{\cftbeforetabskip}{0pt}       
\setlength{\cftaftertoctitleskip}{0pt}   
\renewcommand{\listtablename}{}          
\listoftables
\endgroup
\cleardoublepage

% LIST OF EQUATIONS 
\chapter*{List of Equations}
\addcontentsline{toc}{chapter}{List of Equations}
\vspace*{-2.5cm} 
\begingroup
\normalsize
\setlength{\cftmyequationsnumwidth}{2.5em}  
\setlength{\cftmyequationsindent}{0pt}      
\setlength{\cftbeforemyequationsskip}{0pt}  
\renewcommand{\listequationsname}{}         
\listofmyequations
\endgroup
\cleardoublepage

% LIST OF ALGORITHMS
% The algorithm2e package uses a different command for its list
%\listofalgorithms
%\addcontentsline{toc}{chapter}{List of Algorithms}
%\cleardoublepage

% START OF MAIN CONTENT -
\pagenumbering{arabic}
\setcounter{page}{1}

% -------------------------------
% CHAPTERS
% -------------------------------

% INTRODUCTION
\input{Chapters/Chapter1/Introduction} 
\cleardoublepage

%LITERATURE REVIEW
\input{Chapters/Chapter2/Foundations}
\cleardoublepage

%MTTL FRAMEWORK
\input{Chapters/Chapter3/MTTL-Framework}
\cleardoublepage

%METHODOLOGY
\input{Chapters/Chapter4/Methodology}
\cleardoublepage

%RESULTS
\input{Chapters/Chapter5/Results}
\cleardoublepage

%DISCUSSION
\input{Chapters/Chapter6/Discussion}
\cleardoublepage

%CONCLUSION
\input{Chapters/Chapter7/Conclusion}
\cleardoublepage

%REFERENCES
\cleardoublepage
\chapter*{References}                    
\addcontentsline{toc}{chapter}{References} 
\printbibliography[heading=none]         

% ===================================================================
% APPENDIX 
% ===================================================================

\appendix

\chapter{Experimental Configurations}
\label{app:configs}

This appendix details the configurations for our Single-Task Learning (STL) and Multi-Task Transfer Learning (MTTL) models.

\section{Training and Optimization Strategy}

We applied a \textbf{Hybrid tuning strategy} across all models. The backbone remained frozen except for the final residual block (\texttt{layer4}), which was fine-tuned at a low learning rate ($1 \times 10^{-6}$) to refine high-level features. Task-specific heads and LoRA adapters were trained at a higher rate ($1 \times 10^{-3}$).\\

\noindent Optimization utilized \textbf{AdamW} with a weight decay of $1 \times 10^{-4}$ and \textbf{Automatic Mixed Precision (AMP)}, following a linear warmup and cosine annealing schedule. For model selection, STL training stopped when the primary validation metric plateaued. For MTTL, we used a \textbf{composite score} of weighted task metrics to guide early stopping. We implemented a dual checkpointing system: the backbone was saved based on the best composite score, while individual heads were saved whenever they achieved their specific peak performance.

\section{Model Configurations}

Table~\ref{tab:stl_configs_final} lists the best STL configurations. Table~\ref{tab:mttl_configs_final} outlines the consistent setup used for all MTTL experiments, while Table~\ref{tab:mttl_detailed} provides the specific schedules and weighting schemes for each combination.

\begin{table}[htbp]
	\centering
	\caption{Single-Task Learning (STL) Champion Model Configurations.}
	\label{tab:stl_configs_final}
	\begin{tabular}{l c c c c c c}
		\toprule
		\textbf{Task} & \textbf{Classes} & \textbf{Batch Size} & \textbf{Epochs} & \textbf{LR Head} & \textbf{LR Backbone} & \textbf{Warmup} \\
		\midrule
		Det           & 1 & 16 & 150 & $1 \times 10^{-3}$ & $1 \times 10^{-6}$ & 15 epochs \\
		Det           & 2 & 16 & 150 & $1 \times 10^{-3}$ & $1 \times 10^{-6}$ & 15 epochs \\
		Det           & 3 & 16 & 200 & $1 \times 10^{-3}$ & $1 \times 10^{-6}$ & 20 epochs \\
		\addlinespace
		RoI Classif  & 2 & 16 & 150 & $1 \times 10^{-3}$ & $1 \times 10^{-6}$ & 15 epochs \\
		RoI Classif  & 3 & 16 & 200 & $1 \times 10^{-3}$ & $1 \times 10^{-6}$ & 20 epochs \\
		\addlinespace
		Seg        & -- & 16 & 200 & $1 \times 10^{-3}$ & $1 \times 10^{-6}$ & 20 epochs \\
		Loc& -- & 16 & 200 & $1 \times 10^{-3}$ & $1 \times 10^{-6}$ & 15 epochs \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[htbp]
	\centering
	\caption{Multi-Task Transfer Learning (MTTL) Configurations.}
	\label{tab:mttl_configs_final}
	\begin{tabular}{l l}
		\toprule
		\textbf{Parameter} & \textbf{Value} \\
		\midrule
		Batch Size & 8 (with 2 gradient accumulation steps) \\
		Optimizer & AdamW \\
		Learning Rate (Heads \& Adapters) & $1 \times 10^{-3}$ \\
		Learning Rate (Backbone) & $1 \times 10^{-6}$ \\
		Scheduler & Cosine \\
		\midrule
		\multicolumn{2}{l}{\textit{Task Weighting Schemes (Primary Task Weights)}} \\
		Det + Seg & Det: 0.7, Seg: 0.3 \\
		Det + Loc & Det: 0.7, Loc: 0.3 \\
		Det + RoI (2- or 3-Class) & Det: 0.7, RoI: 0.3 \\
		Det + Seg + Loc & Det: 0.6, Seg: 0.2, Loc: 0.2 \\
		Det + Seg + RoI & Det: 0.6, Seg: 0.2, RoI: 0.2 \\
		Det + Loc + RoI & Det: 0.6, Loc: 0.2, RoI: 0.2 \\
		Det + Seg + Loc + RoI & Det: 0.5, Seg: 0.2, Loc: 0.1, RoI: 0.2 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[htbp]
	\centering
	\caption{Detailed training configurations for MTTL task combinations.}
	\label{tab:mttl_detailed}
	\begin{tabular}{l l l c l}
		\toprule
		\textbf{Tasks} & \textbf{Classes} & \textbf{Epc,W} & \textbf{Patience} & \textbf{Primary Task Weights} \\
		\midrule
		\multicolumn{5}{l}{\textit{\textbf{Combinations with 1-Class Detection}}} \\
		Det + Seg                 & Det: 1          & 250, 25    & 30 & Det: 0.7, Seg: 0.3 \\
		Det + Loc             & Det: 1          & 250, 25   & 30 & Det: 0.7, Loc: 0.3 \\
		Det + Seg + Loc       & Det: 1          & 300, 30   & 30 & Det: 0.6, Seg: 0.2, Loc: 0.2 \\
		\addlinespace
		\multicolumn{5}{l}{\textit{\textbf{Combinations with 2-Class Detection / RoI}}} \\
		Det + Seg                 & Det: 2          & 325, 30   & 30 & Det: 0.7, Seg: 0.3 \\
		Det + Loc             & Det: 2          & 325, 30  & 30 & Det: 0.7, Loc: 0.3 \\
		Det + RoI                 & Det: 2, RoI: 2  & 325, 30  & 30 & Det: 0.7, RoI: 0.3 \\
		Det + Seg + Loc       & Det: 2          & 375, 30   & 35 & Det: 0.6, Seg: 0.2, Loc: 0.2 \\
		Det + Seg + RoI           & Det: 2, RoI: 2  & 375, 30   & 35 & Det: 0.6, Seg: 0.2, RoI: 0.2 \\
		Det + Loc + RoI       & Det: 2, RoI: 2  & 375, 30  & 35 & Det: 0.6, Loc: 0.2, RoI: 0.2 \\
		Det + Seg + Loc + RoI & Det: 2, RoI: 2  & 400, 40  & 40 & Det: 0.5, Seg: 0.2, Loc: 0.1, RoI: 0.2 \\
		\addlinespace
		\multicolumn{5}{l}{\textit{\textbf{Combinations with 3-Class Detection / RoI}}} \\
		Det + Seg                 & Det: 3          & 375, 30   & 40 & Det: 0.7, Seg: 0.3 \\
		Det + Loc             & Det: 3          & 375, 30   & 40 & Det: 0.7, Loc: 0.3 \\
		Det + RoI                 & Det: 3, RoI: 3  & 375, 30   & 40 & Det: 0.7, RoI: 0.3 \\
		Det + Seg + Loc       & Det: 3          & 400, 40   & 40 & Det: 0.6, Seg: 0.2, Loc: 0.2 \\
		Det + Seg + RoI           & Det: 3, RoI: 3  & 400, 40   & 40 & Det: 0.6, Seg: 0.2, RoI: 0.2 \\
		Det + Loc + RoI       & Det: 3, RoI: 3  & 400, 30   & 40 & Det: 0.6, Loc: 0.2, RoI: 0.2 \\
		Det + Seg + Loc + RoI & Det: 3, RoI: 3  & 400, 40   & 40 & Det: 0.5, Seg: 0.2, Loc: 0.1, RoI: 0.2 \\
		\bottomrule
	\end{tabular}
\end{table}

\chapter{Performance Leaderboards for All Tasks}
\label{app:leaderboard}

This appendix summarizes the final performance of all STL and MTTL models. For each primary task, we compare the top STL baseline with the relevant MTTL configurations, for a direct assessment of performance and task synergy. Models are ranked by the most relevant metric F1(Inf) for detection, macro F1 for RoI classification, and Dice for segmentation and heatmap localization.

\section{Detection Performance and Synergy}
Detection was evaluated in 1-, 2-, and 3-class settings. The tables report MTTL performance relative to the strongest STL baseline, with $\Delta$ F1(Inf) highlighting the impact of multi-task learning.

\begin{table}[H]
	\centering
	\caption{MTTL results for \textbf{1-Class Detection}.}
	\label{tab:mttl_1_class_synergy}
	\begin{tabular}{l l c c c c}
		\toprule
		\textbf{Task(s)} & \textbf{Paradigm} & \textbf{mAP@50} & \textbf{F1(Inf)} & \textbf{R(Inf)} & \textbf{P(Inf)} \\
		\midrule
		\textit{Det(1) Baseline} & \textit{STL} & \textbf{0.8260} & \textbf{0.8182} & \textbf{0.8218} & \textbf{0.8146} \\
		\addlinespace
		Det(1)+Seg & MTTL & 0.7885 & 0.7654 (-6.5\%) & 0.6953 & 0.8514 \\
		Det(1)+Loc & MTTL & 0.7367 & 0.7285 (-11.0\%) & 0.7098 & 0.7483 \\
		Det(1)+Seg+Loc & MTTL & 0.7709 & 0.7497 (-8.4\%) & 0.7388 & 0.7609 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{MTTL results for \textbf{2-Class Detection}.}
	\label{tab:mttl_2_class_synergy}
	\begin{tabular}{l l c c c}
		\toprule
		\textbf{Task(s)} & \textbf{Paradigm} & \textbf{mAP@50} & \textbf{F1(Inf)} & \textbf{F1-Macro} \\
		\midrule
		\textit{Det(2) Baseline} & \textit{STL} & 0.5834 & 0.5990 & 0.9274 \\
		\addlinespace
		Det(2)+RoI(2) & MTTL & \textbf{0.6452} & \textbf{0.7810} (+30.4\%) & \textbf{0.9411} \\
		Det(2)+Seg & MTTL & 0.6281 & 0.7464 (+24.6\%) & 0.9330 \\
		Det(2)+Loc & MTTL & 0.6398 & 0.7415 (+23.8\%) & 0.9282 \\
		\addlinespace
		Det(2)+Seg+RoI(2) & MTTL & 0.6113 & 0.6976 (+16.5\%) & 0.9256 \\
		Det(2)+Seg+Loc & MTTL & 0.6025 & 0.6120 (+2.2\%) & 0.9025 \\
		Det(2)+RoI(2)+Loc & MTTL & 0.5958 & 0.6065 (+1.3\%) & 0.8958 \\
		\addlinespace
		Det(2)+Seg+RoI(2)+Loc & MTTL & 0.5872 & 0.6030 (+0.7\%) & 0.8897 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{MTTL results for \textbf{3-Class Detection}.}
	\label{tab:mttl_3_class_synergy}
	\begin{tabular}{l l c c c}
		\toprule
		\textbf{Task(s)} & \textbf{Paradigm} & \textbf{mAP@50} & \textbf{F1(Inf)} & \textbf{F1-Macro} \\
		\midrule
		\textit{Det(3) Baseline} & \textit{STL} & 0.3341 & 0.3791 & 0.8977 \\
		\addlinespace
		Det(3)+RoI(3) & MTTL & \textbf{0.7402} & \textbf{0.7710} (+103.4\%) & \textbf{0.9409} \\
		Det(3)+Seg & MTTL & 0.7013 & 0.7230 (+90.7\%) & 0.9351 \\
		Det(3)+Loc & MTTL & 0.6994 & 0.7034 (+85.6\%) & 0.9195 \\
		\addlinespace
		Det(3)+Seg+RoI(3) & MTTL & 0.7089 & 0.6662 (+75.7\%) & 0.9289 \\
		Det(3)+Loc+RoI(3) & MTTL & 0.7289 & 0.6722 (+77.3\%) & 0.9375 \\
		Det(3)+Seg+Loc & MTTL & 0.6913 & 0.5468 (+44.2\%) & 0.9362 \\
		\addlinespace
		Det(3)+Seg+RoI(3)+Loc & MTTL & 0.7324 & 0.7360 (+94.2\%) & 0.9364 \\
		\bottomrule
	\end{tabular}
\end{table}

\section{Auxiliary Task Leaderboards}
We now present the leaderboards for the auxiliary tasks to evaluate how they perform as standalone specialists (STL) versus when they are part of a larger multi-task system (MTTL).

\begin{table}[H]
	\centering
	\caption{Segmentation Performance Leaderboard (Ranked by Dice).}
	\label{tab:leaderboard_seg}
	\begin{tabular}{l l c c}
		\toprule
		\textbf{Task(s)} & \textbf{Paradigm} & \textbf{Dice} & \textbf{IoU} \\
		\midrule
		Seg & STL & \textbf{0.9656} & \textbf{0.9468} \\
		\addlinespace
		Det(2)+Seg & MTTL & 0.9575 & 0.9332 \\
		Det(3)+Seg & MTTL & 0.9564 & 0.9327 \\
		Det(3)+Seg+RoI(3)+Loc & MTTL & 0.9518 & 0.9293 \\
		Det(2)+Seg+RoI(2) & MTTL & 0.9504 & 0.9264 \\
		Det(3)+Seg+Loc & MTTL & 0.9502 & 0.9276 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Heatmap Localization Performance Leaderboard (Ranked by Dice).}
	\label{tab:leaderboard_loc}
	\begin{tabular}{l l c c c}
		\toprule
		\textbf{Task(s)} & \textbf{Paradigm} & \textbf{Dice} & \textbf{Pearson} & \textbf{MAE} \\
		\midrule
		Loc & STL & \textbf{0.5422} & \textbf{0.7866} & \textbf{0.9719} \\
		\addlinespace
		Det(3)+Loc & MTTL & 0.5108 & 0.7680 & 0.9900 \\
		Det(1)+Seg+Loc & MTTL & 0.5081 & 0.7636 & 0.9893 \\
		Det(3)+Loc+RoI(3) & MTTL & 0.5007 & 0.7571 & 0.9891 \\
		Det(1)+Loc & MTTL & 0.4975 & 0.7541 & 0.9898 \\
		Det(2)+Loc & MTTL & 0.0557 & 0.1698 & 0.5930 \\
		Det(3)+Seg+Loc+RoI(3) & MTTL & 0.0358 & 0.1565 & 0.3221 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{RoI Classification Performance Leaderboard (Ranked by F1-Macro).}
	\label{tab:leaderboard_roi}
	\begin{tabular}{l l c c c}
		\toprule
		\textbf{Task(s)} & \textbf{Paradigm} & \textbf{Classes} & \textbf{Accuracy} & \textbf{F1-Macro} \\
		\midrule
		\multicolumn{5}{l}{\textit{\textbf{2-Class Classification}}} \\
		\addlinespace
		RoI(2) & STL & 2 & \textbf{0.9859} & \textbf{0.9029} \\
		Det(2)+RoI(2) & MTTL & 2 & 0.9832 & 0.9024 \\
		Det(2)+Seg+RoI(2) & MTTL & 2 & 0.9626 & 0.8278 \\
		\addlinespace
		\midrule
		\addlinespace
		\multicolumn{5}{l}{\textit{\textbf{3-Class Classification}}} \\
		\addlinespace
		Det(3)+RoI(3) & MTTL & 3 & \textbf{0.9802} & \textbf{0.9103} \\
		Det(3)+Seg+RoI(3)+Loc & MTTL & 3 & 0.9709 & 0.8732 \\
		Det(3)+Loc+RoI(3) & MTTL & 3 & 0.9470 & 0.8326 \\
		RoI(3) & STL & 3 & 0.9373 & 0.8047 \\
		Det(3)+Seg+RoI(3) & MTTL & 3 & 0.9296 & 0.7618 \\
		\bottomrule
	\end{tabular}
\end{table}

\noindent
\textbf{Observations:} The synergy of MTTL is highly dependent on the complexity of the primary task, in our case object detection. For simple 1-class detection, all auxiliary tasks introduce a performance penalty (ranging from $-6.5\%$ to $-11.0\%$). However, as the task shifts to the more diagnostically realistic 2-class and 3-class problems, MTTL demonstrates its power. For 2-class detection, RoI Classification provides the most significant boost ($+30.4\%$), followed by Segmentation ($+24.6\%$) and Localization ($+23.8\%$). For 3-class detection, RoI Classification becomes the most effective auxiliary task, yielding a remarkable $+103.4\%$ improvement in $F1(\text{Inf})$ over the weak STL baseline, with Segmentation also providing substantial gains ($+90.7\%$) and Localization contributing $+85.6\%$. This highlights that as the primary task becomes more challenging, the regularization and shared representations learned from auxiliary tasks become increasingly beneficial. \\

\noindent
For the auxiliary tasks themselves (Segmentation, Heatmap Localization, and RoI Classification), the specialist STL models consistently outperform their MTTL counterparts on their respective primary metrics. Segmentation achieves $\text{Dice} = 0.9656$ (STL) versus $0.9575$ (best MTTL), Heatmap Localization reaches $\text{Dice} = 0.5422$ (STL) versus $0.5108$ (best MTTL), while RoI Classification shows a notable exception: for 3-class problems, MTTL ($F1 = 0.9103$) surpasses STL ($F1 = 0.8047$) by $+13.1\%$, demonstrating that the shared representations in multi-task learning can benefit auxiliary tasks when the primary task provides complementary supervision. For 2-class RoI Classification, STL and MTTL perform nearly identically ($0.9029$ versus $0.9024$). This pattern reveals a key trade-off: while auxiliary tasks can significantly boost primary task performance (especially in complex scenarios like 3-class detection), they typically do so at the cost of their own specialist performance, as the shared backbone must find a compromise representation serving all tasks simultaneously.

\chapter{Qualitative Examples}
\label{app:qualitative}

This appendix provides qualitative examples to visually complement the quantitative leaderboards in Appendix \ref{app:leaderboard}. We compare the outputs of the best Single-Task (STL) and Multi-Task (MTTL) models against the ground truth for each core task. These visualizations offer tangible insights into the practical strengths and weaknesses of each learning paradigm.

\section{Auxiliary Segmentation and Localization}

We begin by visualizing performance on the pixel- and region-level auxiliary tasks, as their ability to provide spatial priors is critical to the success of MTTL.\\

\noindent For segmentation, Figure \ref{fig:qual_seg} compares the predicted cell masks from the best STL and MTTL models against the ground truth. While both models produce high-quality outputs, the specialist STL model's mask is visibly cleaner and aligns more precisely with the ground truth boundaries. This visual evidence supports the quantitative findings that specialist models achieve peak performance on their designated task, as the shared backbone in MTTL must find a representation that is a compromise across all tasks.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{figures/Qualitative_Seg.png}
	\caption{Qualitative comparison for Cell Segmentation.}
	\label{fig:qual_seg}
\end{figure}

\noindent Both paradigms locate infections (Figures \ref{fig:qual_heatmap1}, \ref{fig:qual_heatmap2}), but the STL maps are sharper. This reflects the trade-off where auxiliary tasks sacrifice their own precision to regularize the primary detector.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\textwidth]{figures/Qualitative_Heatmap_Sample_nlm_0481.png}
	\caption{Qualitative comparison for Heatmap Localization.}
	\label{fig:qual_heatmap1}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\textwidth]{figures/Qualitative_Heatmap_Sample_nlm_0753.png}
	\caption{Qualitative comparison for Heatmap Localization.}
	\label{fig:qual_heatmap2}
\end{figure}

\clearpage
\section{Auxiliary RoI Classification}

To analyze the classification capabilities at a granular level, we perform inference on a curated set of ground truth cell patches. Figure \ref{fig:qual_roi3} shows the cropped cell image alongside the predicted probability distributions from the STL and MTTL models for a 3-class task. Both models demonstrate high accuracy. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.95\textwidth]{figures/Qualitative_RoI_Grid_cls3.png}
	\caption{Qualitative comparison for 3-Class RoI Classification.}
	\label{fig:qual_roi3}
\end{figure}

\clearpage
\section{Detection Performance}

Finally, we visualize the performance on the primary detection task.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{figures/Qualitative_Det_1cls.png}
	\caption{Qualitative comparison for 1-Class Detection.}
	\label{fig:qual_det1}
	\vspace{0.5em}
	\centering
	\begin{tabular}{lll}
		\tikz{\draw[lime, very thick, dashed] (0,0) -- (0.6,0);} Infected (GT) & 
		\tikz{\draw[cyan, very thick, dashed] (0,0) -- (0.6,0);} Healthy (GT) & 
		\tikz{\draw[magenta, very thick, dashed] (0,0) -- (0.6,0);} WBC (GT) \\
		\tikz{\draw[red, very thick] (0,0) -- (0.6,0);} Infected (Pred) & 
		\tikz{\draw[blue, very thick] (0,0) -- (0.6,0);} Healthy (Pred) & 
		\tikz{\draw[violet, very thick] (0,0) -- (0.6,0);} WBC (Pred) \\
	\end{tabular}
\end{figure}

\noindent In the simple 1-class setting (Figure \ref{fig:qual_det1}), the specialist STL model demonstrates excellent precision and recall. The MTTL model, however, produces several false negatives, visually confirming the negative synergy observed in the quantitative results when auxiliary tasks are applied to a simple primary objective.

\noindent As task complexity increases to the diagnostically realistic 3-class problem (Figure \ref{fig:qual_det3}), the limitations of the STL approach become stark. The specialist model struggles to generalize, missing numerous infected cells. The MTTL model, in contrast, leverages the regularizing effects of its auxiliary tasks to maintain robust performance, accurately identifying most cells from all three classes. This figure provides the core visual evidence for our work MTTL is a superior paradigm for developing comprehensive and effective diagnostic models in complex settings.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{figures/Qualitative_Det_2cls.png}
	\caption{Qualitative comparison for 2-Class Detection.}
	\label{fig:qual_det2}
	\vspace{0.5em}
	\centering
	\begin{tabular}{lll}
		\tikz{\draw[lime, very thick, dashed] (0,0) -- (0.6,0);} Infected (GT) & 
		\tikz{\draw[cyan, very thick, dashed] (0,0) -- (0.6,0);} Healthy (GT) & 
		\tikz{\draw[magenta, very thick, dashed] (0,0) -- (0.6,0);} WBC (GT) \\
		\tikz{\draw[red, very thick] (0,0) -- (0.6,0);} Infected (Pred) & 
		\tikz{\draw[blue, very thick] (0,0) -- (0.6,0);} Healthy (Pred) & 
		\tikz{\draw[violet, very thick] (0,0) -- (0.6,0);} WBC (Pred) \\
	\end{tabular}
\end{figure}

\noindent In the most challenging 3-class problem (Figure \ref{fig:qual_det3}), the limitations of the STL approach become stark. The specialist model struggles to generalize, missing numerous infected cells. The MTTL model, in contrast, leverages the regularizing effects of its auxiliary tasks to maintain robust performance, accurately identifying most cells from all three classes. This figure provides the core visual evidence for our work: MTTL is a superior paradigm for developing comprehensive and effective diagnostic models in complex settings.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{figures/Qualitative_Det_3cls.png}
	\caption{Qualitative comparison for 3-Class Detection.}
	\label{fig:qual_det3}
	\vspace{0.5em}
	\centering
	\begin{tabular}{lll}
		\tikz{\draw[lime, very thick, dashed] (0,0) -- (0.6,0);} Infected (GT) & 
		\tikz{\draw[cyan, very thick, dashed] (0,0) -- (0.6,0);} Healthy (GT) & 
		\tikz{\draw[magenta, very thick, dashed] (0,0) -- (0.6,0);} WBC (GT) \\
		\tikz{\draw[red, very thick] (0,0) -- (0.6,0);} Infected (Pred) & 
		\tikz{\draw[blue, very thick] (0,0) -- (0.6,0);} Healthy (Pred) & 
		\tikz{\draw[violet, very thick] (0,0) -- (0.6,0);} WBC (Pred) \\
	\end{tabular}
\end{figure}

\end{document}