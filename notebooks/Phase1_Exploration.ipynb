{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eba5d1a",
   "metadata": {},
   "source": [
    "# Phase 1: Data Loading, Inspection & Understanding\n",
    "\n",
    "This notebook goes through the first phase of the MTTL Malaria Detection experimentation pipeline. We will load, inspect, and analyze your chosen malaria dataset to understand its structure, contents, and label distributions, In this case the NIH-NLM Thin dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c3bf4",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary Python libraries for data handling, visualization, and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41783448",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data root dir\n",
    "NLM_ROOT = os.path.join('..', 'data', 'NIH-NLM-ThinBloodSmearsPf')\n",
    "POINT_SET_DIR = os.path.join(NLM_ROOT, 'Point Set')\n",
    "POLYGON_SET_DIR = os.path.join(NLM_ROOT, 'Polygon Set')\n",
    "\n",
    "# List all patient folders in Point Set and Polygon Set directories\n",
    "point_set_folders = sorted([os.path.join(POINT_SET_DIR, d) for d in os.listdir(POINT_SET_DIR) if os.path.isdir(os.path.join(POINT_SET_DIR, d))])\n",
    "polygon_set_folders = sorted([os.path.join(POLYGON_SET_DIR, d) for d in os.listdir(POLYGON_SET_DIR) if os.path.isdir(os.path.join(POLYGON_SET_DIR, d))])\n",
    "\n",
    "# Print out findings\n",
    "print(f\"Found {len(point_set_folders)} Point Set folders.\")\n",
    "print(f\"Found {len(polygon_set_folders)} Polygon Set folders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f4c6f",
   "metadata": {},
   "source": [
    "## 3. Explore Dataset Structure\n",
    "\n",
    "Inspect the directory structure and file organization. List files, folders, and check for annotation files in the NIH-NLM dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Structure\n",
    "sample_folder = point_set_folders[0] if point_set_folders else None\n",
    "if sample_folder:\n",
    "    print(f\"Sample folder: {sample_folder}\")\n",
    "    subfolders = os.listdir(sample_folder)\n",
    "    print(f\"Subfolders in sample folder: {subfolders}\")\n",
    "    img_dir = os.path.join(sample_folder, 'Img')\n",
    "    gt_dir = os.path.join(sample_folder, 'GT')\n",
    "    if os.path.isdir(img_dir):\n",
    "        print(f\"Images: {os.listdir(img_dir)[:3]} ... (total: {len(os.listdir(img_dir))})\")\n",
    "    if os.path.isdir(gt_dir):\n",
    "        print(f\"Annotation files: {os.listdir(gt_dir)[:3]} ... (total: {len(os.listdir(gt_dir))})\")\n",
    "else:\n",
    "    print(\"No Point Set folders found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d27899",
   "metadata": {},
   "source": [
    "## 4. Extract Dataset Information\n",
    "\n",
    "Parse annotation file or metadata to extract relevant information such as labels, and bounding boxes if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e881138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Annotation Files\n",
    "def parse_point_set_annotations(patient_folders):\n",
    "    annotations = []\n",
    "    for folder in patient_folders:\n",
    "        gt_dir = os.path.join(folder, 'GT')\n",
    "        img_dir = os.path.join(folder, 'Img')\n",
    "        if not os.path.isdir(gt_dir) or not os.path.isdir(img_dir):\n",
    "            continue\n",
    "        for ann_file in os.listdir(gt_dir):\n",
    "            if not ann_file.lower().endswith('.txt'):\n",
    "                continue\n",
    "            ann_path = os.path.join(gt_dir, ann_file)\n",
    "            img_name = ann_file.replace('.txt', '.jpg')\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            with open(ann_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.read().strip().split('\\n')\n",
    "                if len(lines) < 2:\n",
    "                    continue\n",
    "                for line in lines[1:]:\n",
    "                    parts = line.split(',')\n",
    "                    if len(parts) < 7:\n",
    "                        continue\n",
    "                    cell_type = parts[1]\n",
    "                    shape = parts[3]\n",
    "                    if shape == 'Point':\n",
    "                        x = float(parts[5])\n",
    "                        y = float(parts[6])\n",
    "                        annotations.append({\n",
    "                            'image_path': img_path,\n",
    "                            'cell_type': cell_type,\n",
    "                            'shape': shape,\n",
    "                            'x': x,\n",
    "                            'y': y\n",
    "                        })\n",
    "                    elif shape == 'Polygon':\n",
    "                        n_points = int(parts[4])\n",
    "                        coords = [float(v) for v in parts[5:5+2*n_points]]\n",
    "                        xy = list(zip(coords[::2], coords[1::2]))\n",
    "                        # Calculate bounding box for polygon like [ min(x), min(y), max(x), max(y) ]\n",
    "                        xs, ys = zip(*xy)\n",
    "                        bbox = [min(xs), min(ys), max(xs), max(ys)]\n",
    "                        annotations.append({\n",
    "                            'image_path': img_path,\n",
    "                            'cell_type': cell_type,\n",
    "                            'shape': shape,\n",
    "                            'polygon': xy,\n",
    "                            'bbox': bbox\n",
    "                        })\n",
    "    return annotations\n",
    "\n",
    "annotations = parse_point_set_annotations(point_set_folders)\n",
    "print(f\"Parsed {len(annotations)} cell annotations from Point Set.\")\n",
    "if annotations:\n",
    "    print(\"Sample annotation:\", annotations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370f49ae",
   "metadata": {},
   "source": [
    "## 5. Identify Classes and Labels\n",
    "\n",
    "Identify all available classes and labels in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b89eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all unique classes/labels \n",
    "if annotations:\n",
    "    all_labels = [row['cell_type'] for row in annotations]\n",
    "    unique_classes = sorted(set(all_labels))\n",
    "    print(f\"Found {len(unique_classes)} unique classes:\")\n",
    "    for c in unique_classes:\n",
    "        print(f\"- {c}\")\n",
    "else:\n",
    "    print(\"No annotation data to extract classes from.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805faa2",
   "metadata": {},
   "source": [
    "## 6. Calculate Class Distribution and Statistics\n",
    "\n",
    "Compute the number of samples per class and display class distribution statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a79fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class distribution (corrected for new annotation structure)\n",
    "if annotations:\n",
    "    class_counts = Counter(all_labels)\n",
    "    class_dist_df = pd.DataFrame({\n",
    "        'Class': list(class_counts.keys()),\n",
    "        'Count': list(class_counts.values())\n",
    "    }).sort_values('Count', ascending=False)\n",
    "    print(class_dist_df)\n",
    "else:\n",
    "    print(\"No annotation data to compute class distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f0506",
   "metadata": {},
   "source": [
    "## 7. Plot Sample Images with Annotations\n",
    "\n",
    "Visualize a few sample images from the dataset with their corresponding annotations (e.g., bounding boxes, labels) overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed0e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize an image sample with annotations\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Color map and labels\n",
    "cell_type_colors = {\n",
    "    'Parasitized': 'red',\n",
    "    'Uninfected': 'lime',\n",
    "    'White_Blood_Cell': 'blue'\n",
    "}\n",
    "cell_type_short = {\n",
    "    'Parasitized': 'P',\n",
    "    'Uninfected': 'U',\n",
    "    'White_Blood_Cell': 'W'\n",
    "}\n",
    "\n",
    "if annotations:\n",
    "    image_to_anns = defaultdict(list)\n",
    "    for ann in annotations:\n",
    "        image_to_anns[ann['image_path']].append(ann)\n",
    "    image_paths = list(image_to_anns.keys())\n",
    "    if image_paths:\n",
    "        img_path = random.choice(image_paths)\n",
    "        anns = image_to_anns[img_path]\n",
    "        if os.path.exists(img_path):\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "            fig, ax = plt.subplots(figsize=(7, 7))\n",
    "            ax.imshow(img)\n",
    "            for ann in anns:\n",
    "                color = cell_type_colors.get(ann['cell_type'], 'yellow')\n",
    "                short_label = cell_type_short.get(ann['cell_type'], '?')\n",
    "                if ann['shape'] == 'Point':\n",
    "                    ax.plot(ann['x'], ann['y'], 'o', color=color, markersize=10, markeredgewidth=2, markeredgecolor='black')\n",
    "                    ax.text(ann['x']+8, ann['y']-8, short_label, color=color, fontsize=13, weight='bold',\n",
    "                            bbox=dict(facecolor='white', alpha=0.7, edgecolor=color, boxstyle='round,pad=0.2'))\n",
    "                elif ann['shape'] == 'Polygon':\n",
    "                    poly = np.array(ann['polygon'])\n",
    "                    patch = patches.Polygon(poly, closed=True, fill=False, edgecolor=color, linewidth=2)\n",
    "                    ax.add_patch(patch)\n",
    "                    min_x, min_y, max_x, max_y = ann['bbox']\n",
    "                    rect = patches.Rectangle((min_x, min_y), max_x-min_x, max_y-min_y, fill=False, edgecolor=color, linewidth=1, linestyle='dashed')\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.text(min_x, min_y-10, short_label, color=color, fontsize=13, weight='bold',\n",
    "                            bbox=dict(facecolor='white', alpha=0.7, edgecolor=color, boxstyle='round,pad=0.2'))\n",
    "            ax.axis('off')\n",
    "            handles = [patches.Patch(color=clr, label=lbl) for lbl, clr in zip(['P','U','W'], cell_type_colors.values())]\n",
    "            plt.legend(handles=handles, labels=['P: Parasitized','U: Uninfected','W: WBC'], loc='lower center', frameon=True, fontsize=12, bbox_to_anchor=(0.5, -0.08), ncol=3)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Image not found: {img_path}\")\n",
    "    else:\n",
    "        print(\"No images found in annotations.\")\n",
    "else:\n",
    "    print(\"No annotation data to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e63ebd",
   "metadata": {},
   "source": [
    "## Visualize More Images with Annotations\n",
    "\n",
    "Display a grid of random images from the dataset, each with bounding boxes and class labels overlaid. This helps visually inspect annotation quality and class diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a grid of random images with colored annotations and minimal labels (by cell type)\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define a color map and minimal label map for cell types\n",
    "cell_type_colors = {\n",
    "    'Parasitized': 'red',\n",
    "    'Uninfected': 'lime',\n",
    "    'White_Blood_Cell': 'blue'\n",
    "}\n",
    "cell_type_short = {\n",
    "    'Parasitized': 'P',\n",
    "    'Uninfected': 'U',\n",
    "    'White_Blood_Cell': 'W'\n",
    "}\n",
    "\n",
    "def plot_image_grid_with_annotations(annotations, n_images=8, ncols=4):\n",
    "    if not annotations:\n",
    "        print(\"No annotations to display.\")\n",
    "        return\n",
    "\n",
    "    from collections import defaultdict\n",
    "    image_to_anns = defaultdict(list)\n",
    "    for ann in annotations:\n",
    "        image_to_anns[ann['image_path']].append(ann)\n",
    "\n",
    "    image_paths = list(image_to_anns.keys())\n",
    "    sample_paths = random.sample(image_paths, min(n_images, len(image_paths)))\n",
    "    nrows = (len(sample_paths) + ncols - 1) // ncols\n",
    "\n",
    "    plt.figure(figsize=(ncols * 4, nrows * 4))\n",
    "    for idx, img_path in enumerate(sample_paths):\n",
    "        anns = image_to_anns[img_path]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            continue\n",
    "        ax = plt.subplot(nrows, ncols, idx + 1)\n",
    "        ax.imshow(img)\n",
    "        for ann in anns:\n",
    "            color = cell_type_colors.get(ann['cell_type'], 'yellow')\n",
    "            short_label = cell_type_short.get(ann['cell_type'], '?')\n",
    "            if ann['shape'] == 'Point':\n",
    "                ax.plot(ann['x'], ann['y'], 'o', color=color, markersize=8, markeredgewidth=2, markeredgecolor='black')\n",
    "                ax.text(ann['x']+6, ann['y']-6, short_label, color=color, fontsize=11, weight='bold', bbox=dict(facecolor='white', alpha=0.7, edgecolor=color, boxstyle='round,pad=0.2'))\n",
    "            elif ann['shape'] == 'Polygon':\n",
    "                poly = np.array(ann['polygon'])\n",
    "                patch = patches.Polygon(poly, closed=True, fill=False, edgecolor=color, linewidth=2)\n",
    "                ax.add_patch(patch)\n",
    "                min_x, min_y = poly.min(axis=0)\n",
    "                max_x, max_y = poly.max(axis=0)\n",
    "                rect = patches.Rectangle((min_x, min_y), max_x-min_x, max_y-min_y, fill=False, edgecolor=color, linewidth=1, linestyle='dashed')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(min_x, min_y-8, short_label, color=color, fontsize=11, weight='bold', bbox=dict(facecolor='white', alpha=0.7, edgecolor=color, boxstyle='round,pad=0.2'))\n",
    "        ax.set_title(os.path.basename(img_path))\n",
    "        ax.axis('off')\n",
    "    # Add legend with minimal labels\n",
    "    handles = [patches.Patch(color=clr, label=lbl) for lbl, clr in zip(['P','U','W'], cell_type_colors.values())]\n",
    "    plt.figlegend(handles=handles, labels=['P: Parasitized','U: Uninfected','W: WBC'], loc='lower center', ncol=3, frameon=True, fontsize=12)\n",
    "    plt.tight_layout(rect=[0,0.05,1,1])\n",
    "    plt.show()\n",
    "\n",
    "plot_image_grid_with_annotations(annotations, n_images=4, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe47a92c",
   "metadata": {},
   "source": [
    "## 8. Analyze Label Distribution\n",
    "\n",
    "Create bar charts and summary statistics to analyze the distribution of labels across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a1854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class distribution \n",
    "if annotations:\n",
    "    class_counts = Counter(all_labels)\n",
    "    class_dist_df = pd.DataFrame({\n",
    "        'Class': list(class_counts.keys()),\n",
    "        'Count': list(class_counts.values())\n",
    "    }).sort_values('Count', ascending=False)\n",
    "    print(class_dist_df)\n",
    "else:\n",
    "    print(\"No annotation data to compute class distribution.\")\n",
    "\n",
    "# Bar chart of class distribution\n",
    "if annotations and class_dist_df is not None:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(data=class_dist_df, x='Class', y='Count', palette='viridis')\n",
    "    plt.title('Class Distribution in NIH-NLM Dataset')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No class distribution data to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3689c2a",
   "metadata": {},
   "source": [
    "## 9. Dataset Statistics & Insights\n",
    "\n",
    "Summarize key statistics about the dataset, such as:\n",
    "- Total number of images\n",
    "- Total number of annotated objects\n",
    "- Number of unique classes\n",
    "- Images per class (min, max, mean)\n",
    "- Any notable class imbalance or annotation issues\n",
    "\n",
    "Present these as a table or bullet points for quick reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display dataset statistics & insights\n",
    "from collections import Counter\n",
    "\n",
    "def dataset_statistics(annotations, class_dist_df):\n",
    "    if not annotations or class_dist_df is None:\n",
    "        print(\"No annotation data available.\")\n",
    "        return\n",
    "    \n",
    "    total_images = len(set([ann['image_path'] for ann in annotations]))\n",
    "    total_objects = len(annotations)\n",
    "    unique_classes = class_dist_df['Class'].nunique()\n",
    "    class_counts = class_dist_df.set_index('Class')['Count'].to_dict()\n",
    "    min_per_class = class_dist_df['Count'].min()\n",
    "    max_per_class = class_dist_df['Count'].max()\n",
    "    mean_per_class = class_dist_df['Count'].mean()\n",
    "    \n",
    "    print(f\"Total images: {total_images}\")\n",
    "    print(f\"Total annotated objects: {total_objects}\")\n",
    "    print(f\"Unique classes: {unique_classes}\")\n",
    "    print(f\"Images per class (min/mean/max): {min_per_class} / {mean_per_class:.2f} / {max_per_class}\")\n",
    "    print(\"\\nClass counts:\")\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"  {cls}: {count}\")\n",
    "    \n",
    "    # class imbalance check\n",
    "    imbalance_ratio = max_per_class / min_per_class if min_per_class > 0 else float('inf')\n",
    "    if imbalance_ratio > 2:\n",
    "        print(f\"\\nWarning: Class imbalance detected (max/min ratio = {imbalance_ratio:.2f})\")\n",
    "    else:\n",
    "        print(\"\\nNo severe class imbalance detected.\")\n",
    "\n",
    "dataset_statistics(annotations, class_dist_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
